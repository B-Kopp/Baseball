{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLB 2020 WAR Predictions\n",
    "\n",
    "Using a download of all available batter statistics on [Fangraphs](https://www.fangraphs.com) from 2006-2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bill\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (87) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5381, 305)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import Data\n",
    "data = pd.read_csv('input/FanGraphsData.csv')\n",
    "\n",
    "# Format some of the columns\n",
    "for col in data.columns:\n",
    "    if (data[col].dtype == object) & ('%' in col):\n",
    "        data[col] = data[col].str.strip('%').astype('float64')\n",
    "data['Dol'] = data['Dol'].str.strip('$()').astype('float64')\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Age</th>\n",
       "      <th>G</th>\n",
       "      <th>AB</th>\n",
       "      <th>PA</th>\n",
       "      <th>H</th>\n",
       "      <th>1B</th>\n",
       "      <th>2B</th>\n",
       "      <th>...</th>\n",
       "      <th>GB%+</th>\n",
       "      <th>FB%+</th>\n",
       "      <th>HR/FB%+</th>\n",
       "      <th>Pull%+</th>\n",
       "      <th>Cent%+</th>\n",
       "      <th>Oppo%+</th>\n",
       "      <th>Soft%+</th>\n",
       "      <th>Med%+</th>\n",
       "      <th>Hard%+</th>\n",
       "      <th>playerid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2008</td>\n",
       "      <td>Albert Pujols</td>\n",
       "      <td>Cardinals</td>\n",
       "      <td>28</td>\n",
       "      <td>148</td>\n",
       "      <td>524</td>\n",
       "      <td>641</td>\n",
       "      <td>187</td>\n",
       "      <td>106</td>\n",
       "      <td>44</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>105</td>\n",
       "      <td>193</td>\n",
       "      <td>117</td>\n",
       "      <td>94</td>\n",
       "      <td>81</td>\n",
       "      <td>92</td>\n",
       "      <td>75</td>\n",
       "      <td>154</td>\n",
       "      <td>1177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "      <td>Travis Hafner</td>\n",
       "      <td>Indians</td>\n",
       "      <td>29</td>\n",
       "      <td>129</td>\n",
       "      <td>454</td>\n",
       "      <td>564</td>\n",
       "      <td>140</td>\n",
       "      <td>66</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>88</td>\n",
       "      <td>110</td>\n",
       "      <td>280</td>\n",
       "      <td>102</td>\n",
       "      <td>105</td>\n",
       "      <td>89</td>\n",
       "      <td>67</td>\n",
       "      <td>85</td>\n",
       "      <td>146</td>\n",
       "      <td>1573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2007</td>\n",
       "      <td>David Ortiz</td>\n",
       "      <td>Red Sox</td>\n",
       "      <td>31</td>\n",
       "      <td>149</td>\n",
       "      <td>549</td>\n",
       "      <td>667</td>\n",
       "      <td>182</td>\n",
       "      <td>94</td>\n",
       "      <td>52</td>\n",
       "      <td>...</td>\n",
       "      <td>85</td>\n",
       "      <td>120</td>\n",
       "      <td>183</td>\n",
       "      <td>118</td>\n",
       "      <td>83</td>\n",
       "      <td>95</td>\n",
       "      <td>58</td>\n",
       "      <td>87</td>\n",
       "      <td>143</td>\n",
       "      <td>745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2006</td>\n",
       "      <td>Albert Pujols</td>\n",
       "      <td>Cardinals</td>\n",
       "      <td>26</td>\n",
       "      <td>143</td>\n",
       "      <td>535</td>\n",
       "      <td>634</td>\n",
       "      <td>177</td>\n",
       "      <td>94</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>87</td>\n",
       "      <td>120</td>\n",
       "      <td>204</td>\n",
       "      <td>111</td>\n",
       "      <td>100</td>\n",
       "      <td>82</td>\n",
       "      <td>70</td>\n",
       "      <td>94</td>\n",
       "      <td>125</td>\n",
       "      <td>1177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2008</td>\n",
       "      <td>Chipper Jones</td>\n",
       "      <td>Braves</td>\n",
       "      <td>36</td>\n",
       "      <td>128</td>\n",
       "      <td>439</td>\n",
       "      <td>534</td>\n",
       "      <td>160</td>\n",
       "      <td>113</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>92</td>\n",
       "      <td>163</td>\n",
       "      <td>95</td>\n",
       "      <td>108</td>\n",
       "      <td>97</td>\n",
       "      <td>66</td>\n",
       "      <td>102</td>\n",
       "      <td>116</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 305 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season           Name       Team  Age    G   AB   PA    H   1B  2B  ...  \\\n",
       "0    2008  Albert Pujols  Cardinals   28  148  524  641  187  106  44  ...   \n",
       "1    2006  Travis Hafner    Indians   29  129  454  564  140   66  31  ...   \n",
       "2    2007    David Ortiz    Red Sox   31  149  549  667  182   94  52  ...   \n",
       "3    2006  Albert Pujols  Cardinals   26  143  535  634  177   94  33  ...   \n",
       "4    2008  Chipper Jones     Braves   36  128  439  534  160  113  24  ...   \n",
       "\n",
       "   GB%+  FB%+  HR/FB%+  Pull%+  Cent%+  Oppo%+  Soft%+  Med%+  Hard%+  \\\n",
       "0    92   105      193     117      94      81      92     75     154   \n",
       "1    88   110      280     102     105      89      67     85     146   \n",
       "2    85   120      183     118      83      95      58     87     143   \n",
       "3    87   120      204     111     100      82      70     94     125   \n",
       "4    99    92      163      95     108      97      66    102     116   \n",
       "\n",
       "   playerid  \n",
       "0      1177  \n",
       "1      1573  \n",
       "2       745  \n",
       "3      1177  \n",
       "4        97  \n",
       "\n",
       "[5 rows x 305 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are going to predict a player's WAR based on previous seasons we need to get rid of the rookies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts = data['playerid'].value_counts()\n",
    "to_remove = value_counts[value_counts == 1].index\n",
    "data = data[~data.playerid.isin(to_remove)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will then create a column for the WAR from the next season. We need to fill this with the actual next season WAR for seasons prior to 2019 and leave it to be predicted for the 2019 season. This will be our label for the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3881, 306)\n",
      "(324, 306)\n"
     ]
    }
   ],
   "source": [
    "data = data.merge(data.assign(Season=lambda x: x.Season - 1),\n",
    "                 on=['Season', 'playerid'],\n",
    "                 suffixes = ['','_new'],\n",
    "                 how='left')\n",
    "data = data.rename(columns={'WAR_new': 'WAR_label'})\n",
    "data = data.drop(data.filter(regex='_new').columns, axis=1)\n",
    "test = data[data.Season == 2019].reset_index(drop=True)\n",
    "train = data.dropna(subset=['WAR_label'])\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will then drop the columns with > 30% nulls while imputing the rest of the nulls using the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_percent = train.isnull().sum()/train.shape[0]*100\n",
    "cols_to_drop = np.array(null_percent[null_percent > 30].index)\n",
    "train = train.drop(cols_to_drop, axis=1)\n",
    "test = test.drop(cols_to_drop,axis=1)\n",
    "null_percent = train.isnull().sum()/train.shape[0]*100\n",
    "null_cols = list(null_percent[null_percent > 0].index.values)\n",
    "\n",
    "for i in null_cols:\n",
    "    train[i] = train[i].replace(np.nan, train[i].mean())\n",
    "    test[i] = test[i].replace(np.nan, train[i].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will save these as our train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('input/Batter1Train.csv', index=False, header=True)\n",
    "test.to_csv('input/Batter1Test.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will complete the same process but instead of using the previous year to predict with, we will use the previous 2 years of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2914, 606)\n",
      "(298, 606)\n"
     ]
    }
   ],
   "source": [
    "data2 = data.copy()\n",
    "data2 = data2.merge(data2.assign(Season=lambda x: x.Season + 1),\n",
    "                 on=['Season', 'playerid'],\n",
    "                 suffixes = ['','_lastyr'],\n",
    "                 how='left')\n",
    "column_list = list(data2)\n",
    "\n",
    "for i in range(4,304):\n",
    "    data2[column_list[i]+'_diff'] = data2[column_list[i]] - data2[column_list[i+305]]\n",
    "    \n",
    "data2 = data2.drop(data2.filter(regex='_lastyr').columns, axis=1)\n",
    "data2 = data2.dropna(thresh=295)\n",
    "\n",
    "test2 = data2[data2.Season == 2019].reset_index(drop=True)\n",
    "train2 = data2.dropna(subset=['WAR_label'])\n",
    "print(train2.shape)\n",
    "print(test2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_percent = train2.isnull().sum()/train2.shape[0]*100\n",
    "cols_to_drop = np.array(null_percent[null_percent > 30].index)\n",
    "train2 = train2.drop(cols_to_drop, axis=1)\n",
    "test2 = test2.drop(cols_to_drop,axis=1)\n",
    "null_percent = train2.isnull().sum()/train2.shape[0]*100\n",
    "null_cols = list(null_percent[null_percent > 0].index.values)\n",
    "\n",
    "for i in null_cols:\n",
    "    train2[i] = train2[i].replace(np.nan, train2[i].mean())\n",
    "    test2[i] = test2[i].replace(np.nan, train2[i].mean())\n",
    "    \n",
    "train2.to_csv('input/Batter2Train.csv', index=False, header=True)\n",
    "test2.to_csv('input/Batter2Test.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pitchers\n",
    "\n",
    "We will complete the same steps to prepare our pitcher data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bill\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (90) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4642, 322)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Season</th>\n",
       "      <th>Name</th>\n",
       "      <th>Team</th>\n",
       "      <th>Age</th>\n",
       "      <th>W</th>\n",
       "      <th>L</th>\n",
       "      <th>ERA</th>\n",
       "      <th>G</th>\n",
       "      <th>GS</th>\n",
       "      <th>CG</th>\n",
       "      <th>...</th>\n",
       "      <th>GB%+</th>\n",
       "      <th>FB%+</th>\n",
       "      <th>HR/FB%+</th>\n",
       "      <th>Pull%+</th>\n",
       "      <th>Cent%+</th>\n",
       "      <th>Oppo%+</th>\n",
       "      <th>Soft%+</th>\n",
       "      <th>Med%+</th>\n",
       "      <th>Hard%+</th>\n",
       "      <th>playerid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "      <td>Dennys Reyes</td>\n",
       "      <td>Twins</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.89</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>160</td>\n",
       "      <td>55</td>\n",
       "      <td>108</td>\n",
       "      <td>101</td>\n",
       "      <td>110</td>\n",
       "      <td>86</td>\n",
       "      <td>114</td>\n",
       "      <td>115</td>\n",
       "      <td>62</td>\n",
       "      <td>444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2006</td>\n",
       "      <td>Jonathan Papelbon</td>\n",
       "      <td>Red Sox</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.92</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>86</td>\n",
       "      <td>124</td>\n",
       "      <td>37</td>\n",
       "      <td>84</td>\n",
       "      <td>87</td>\n",
       "      <td>142</td>\n",
       "      <td>88</td>\n",
       "      <td>113</td>\n",
       "      <td>76</td>\n",
       "      <td>5975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>Brad Ziegler</td>\n",
       "      <td>Athletics</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.06</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>148</td>\n",
       "      <td>51</td>\n",
       "      <td>65</td>\n",
       "      <td>104</td>\n",
       "      <td>98</td>\n",
       "      <td>96</td>\n",
       "      <td>86</td>\n",
       "      <td>109</td>\n",
       "      <td>91</td>\n",
       "      <td>7293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2006</td>\n",
       "      <td>Cla Meredith</td>\n",
       "      <td>Padres</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.07</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>157</td>\n",
       "      <td>42</td>\n",
       "      <td>130</td>\n",
       "      <td>104</td>\n",
       "      <td>118</td>\n",
       "      <td>70</td>\n",
       "      <td>148</td>\n",
       "      <td>103</td>\n",
       "      <td>72</td>\n",
       "      <td>7613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2008</td>\n",
       "      <td>Joe Nathan</td>\n",
       "      <td>Twins</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.33</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>108</td>\n",
       "      <td>90</td>\n",
       "      <td>94</td>\n",
       "      <td>95</td>\n",
       "      <td>125</td>\n",
       "      <td>77</td>\n",
       "      <td>72</td>\n",
       "      <td>95</td>\n",
       "      <td>127</td>\n",
       "      <td>1122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 322 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Season               Name       Team  Age  W  L   ERA   G  GS  CG  ...  \\\n",
       "0    2006       Dennys Reyes      Twins   29  5  0  0.89  66   0   0  ...   \n",
       "1    2006  Jonathan Papelbon    Red Sox   25  4  2  0.92  59   0   0  ...   \n",
       "2    2008       Brad Ziegler  Athletics   28  3  0  1.06  47   0   0  ...   \n",
       "3    2006       Cla Meredith     Padres   23  5  1  1.07  45   0   0  ...   \n",
       "4    2008         Joe Nathan      Twins   33  1  2  1.33  68   0   0  ...   \n",
       "\n",
       "   GB%+  FB%+  HR/FB%+  Pull%+  Cent%+  Oppo%+  Soft%+  Med%+  Hard%+  \\\n",
       "0   160    55      108     101     110      86     114    115      62   \n",
       "1    86   124       37      84      87     142      88    113      76   \n",
       "2   148    51       65     104      98      96      86    109      91   \n",
       "3   157    42      130     104     118      70     148    103      72   \n",
       "4   108    90       94      95     125      77      72     95     127   \n",
       "\n",
       "   playerid  \n",
       "0       444  \n",
       "1      5975  \n",
       "2      7293  \n",
       "3      7613  \n",
       "4      1122  \n",
       "\n",
       "[5 rows x 322 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pitcher_data = pd.read_csv('input/FanGraphsPitcherData.csv')\n",
    "for col in pitcher_data.columns:\n",
    "    if (pitcher_data[col].dtype == object) & ('%' in col):\n",
    "        pitcher_data[col] = pitcher_data[col].str.strip('%').astype('float64')\n",
    "pitcher_data['Dollars'] = pitcher_data['Dollars'].str.strip('$()').astype('float64')\n",
    "print(pitcher_data.shape)\n",
    "pitcher_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2898, 323)\n",
      "(272, 323)\n"
     ]
    }
   ],
   "source": [
    "value_counts = pitcher_data['playerid'].value_counts()\n",
    "to_remove = value_counts[value_counts == 1].index\n",
    "pitcher_data = pitcher_data[~pitcher_data.playerid.isin(to_remove)]\n",
    "\n",
    "pitcher_data = pitcher_data.merge(pitcher_data.assign(Season=lambda x: x.Season - 1),\n",
    "                 on=['Season', 'playerid'],\n",
    "                 suffixes = ['','_new'],\n",
    "                 how='left')\n",
    "\n",
    "pitcher_data = pitcher_data.rename(columns={'WAR_new': 'WAR_label'})\n",
    "pitcher_data = pitcher_data.drop(pitcher_data.filter(regex='_new').columns, axis=1)\n",
    "\n",
    "pitcher_test = pitcher_data[pitcher_data.Season == 2019].reset_index(drop=True)\n",
    "pitcher_train = pitcher_data.dropna(subset=['WAR_label'])\n",
    "print(pitcher_train.shape)\n",
    "print(pitcher_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_percent = pitcher_train.isnull().sum()/pitcher_train.shape[0]*100\n",
    "cols_to_drop = np.array(null_percent[null_percent > 30].index)\n",
    "pitcher_train = pitcher_train.drop(cols_to_drop, axis=1)\n",
    "pitcher_test = pitcher_test.drop(cols_to_drop,axis=1)\n",
    "\n",
    "null_percent = pitcher_train.isnull().sum()/pitcher_train.shape[0]*100\n",
    "null_cols = list(null_percent[null_percent > 0].index.values)\n",
    "\n",
    "for i in null_cols:\n",
    "    pitcher_train[i] = pitcher_train[i].replace(np.nan, pitcher_train[i].mean())\n",
    "    pitcher_test[i] = pitcher_test[i].replace(np.nan, pitcher_train[i].mean())\n",
    "    \n",
    "pitcher_train.to_csv('input/Pitcher1Train.csv', index=False, header=True)\n",
    "pitcher_test.to_csv('input/Pitcher1Test.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1904, 640)\n",
      "(223, 640)\n"
     ]
    }
   ],
   "source": [
    "pitcher_data2 = pitcher_data.copy()\n",
    "pitcher_data2 = pitcher_data2.merge(pitcher_data2.assign(Season=lambda x: x.Season + 1),\n",
    "                 on=['Season', 'playerid'],\n",
    "                 suffixes = ['','_lastyr'],\n",
    "                 how='left')\n",
    "\n",
    "column_list = list(pitcher_data2)\n",
    "\n",
    "for i in range(4,321):\n",
    "    pitcher_data2[column_list[i]+'_diff'] = pitcher_data2[column_list[i]] - pitcher_data2[column_list[i+322]]\n",
    "    \n",
    "pitcher_data2 = pitcher_data2.drop(pitcher_data2.filter(regex='_lastyr').columns, axis=1)\n",
    "pitcher_data2 = pitcher_data2.dropna(thresh=295)\n",
    "\n",
    "pitcher_test2 = pitcher_data2[pitcher_data2.Season == 2019].reset_index(drop=True)\n",
    "pitcher_train2 = pitcher_data2.dropna(subset=['WAR_label'])\n",
    "print(pitcher_train2.shape)\n",
    "print(pitcher_test2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_percent = pitcher_train2.isnull().sum()/pitcher_train2.shape[0]*100\n",
    "cols_to_drop = np.array(null_percent[null_percent > 30].index)\n",
    "pitcher_train2 = pitcher_train2.drop(cols_to_drop, axis=1)\n",
    "pitcher_test2 = pitcher_test2.drop(cols_to_drop,axis=1)\n",
    "\n",
    "null_percent = pitcher_train2.isnull().sum()/pitcher_train2.shape[0]*100\n",
    "null_cols = list(null_percent[null_percent > 0].index.values)\n",
    "\n",
    "for i in null_cols:\n",
    "    pitcher_train2[i] = pitcher_train2[i].replace(np.nan, pitcher_train2[i].mean())\n",
    "    pitcher_test2[i] = pitcher_test2[i].replace(np.nan, pitcher_train2[i].mean())\n",
    "    \n",
    "pitcher_train2.to_csv('input/Pitcher2Train.csv', index=False, header=True)\n",
    "pitcher_test2.to_csv('input/Pitcher2Test.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "\n",
    "We will begin our modeling by exploring which is the best model from each category of models (Linear, Tree, Support Vector Machine, Nearest Neighbor, Neural Network, and Boosting)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import operator\n",
    "import time\n",
    "import itertools\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.linear_model import Lasso, LinearRegression, Ridge, ElasticNet, LassoLars, BayesianRidge, SGDRegressor, PassiveAggressiveRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor, ExtraTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import VotingRegressor, GradientBoostingRegressor, AdaBoostRegressor, ExtraTreesRegressor, RandomForestRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "seed=1215"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data files\n",
    "player = ['Batter', 'Pitcher']\n",
    "partition = ['Train', 'Test']\n",
    "\n",
    "for k in player:\n",
    "    for j in range(1,3):\n",
    "        for i in partition:\n",
    "            j=str(j)\n",
    "            exec(k+j+'_'+i+' = pd.read_csv(\"input/'+k+j+i+'.csv\")')\n",
    "        exec(k+j+'_Target = '+k+j+'_Train[\"WAR_label\"]')\n",
    "        exec(k+j+\"_Train = \"+k+j+\"_Train.drop(['Name', 'WAR_label', 'playerid', 'Season', 'Team'], axis=1)\")\n",
    "        exec(\"predictions_\"+k[0].lower()+j+\" = \"+k+j+\"_Test[['Name']].copy()\")\n",
    "        exec(k+j+\"_Test = \"+k+j+\"_Test.drop(['Name', 'WAR_label', 'playerid', 'Season', 'Team'], axis=1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "for i in player:\n",
    "    for j in range(1,3):\n",
    "        j=str(j)\n",
    "        exec(i+j+'_Train_scaled = scaler.fit_transform('+i+j+'_Train)')\n",
    "        exec(i+j+'_Test_scaled = scaler.transform('+i+j+'_Test)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From https://github.com/codiply/blog-ipython-notebooks/blob/master/scikit-learn-estimator-selection-helper.ipynb\n",
    "# An easy way to compare grid searched models\n",
    "\n",
    "class EstimatorSelectionHelper:\n",
    "    \n",
    "    def __init__(self, models, params):\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.keys = models.keys()\n",
    "        self.grid_searches = {}\n",
    "    \n",
    "    def fit(self, X, y, **grid_kwargs):\n",
    "        for key in self.keys:\n",
    "            print('Running GridSearchCV for %s.' % key)\n",
    "            model = self.models[key]\n",
    "            params = self.params[key]\n",
    "            grid_search = GridSearchCV(model, params, **grid_kwargs)\n",
    "            grid_search.fit(X, y)\n",
    "            self.grid_searches[key] = grid_search\n",
    "        print('Done.')\n",
    "    \n",
    "    def score_summary(self, sort_by='mean_test_score'):\n",
    "        frames = []\n",
    "        for name, grid_search in self.grid_searches.items():\n",
    "            frame = pd.DataFrame(grid_search.cv_results_)\n",
    "            frame = frame.filter(regex='^(?!.*param_).*$')\n",
    "            frame['estimator'] = len(frame)*[name]\n",
    "            frames.append(frame)\n",
    "        df = pd.concat(frames)\n",
    "        \n",
    "        df = df.sort_values([sort_by], ascending=False)\n",
    "        df = df.reset_index()\n",
    "        df = df.drop(['rank_test_score', 'index'], 1)\n",
    "        \n",
    "        columns = df.columns.tolist()\n",
    "        columns.remove('estimator')\n",
    "        columns = ['estimator']+columns\n",
    "        df = df[columns]\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid of parameters for each of the models\n",
    "\n",
    "params = { \n",
    "    'Linear Regression': {},\n",
    "    'Lasso': {'alpha': np.logspace(-3,2,23)},\n",
    "    'LassoLars': {'alpha': np.logspace(-3,2,23)},\n",
    "    'Ridge': {'alpha': np.logspace(-3,2,11), 'solver': ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg']},\n",
    "    'ElasticNet': {'alpha': np.logspace(-3,2,11), 'l1_ratio': np.linspace(0.05,0.9,18)},\n",
    "    'BayesianRidge': {'alpha_1': np.logspace(-8,-4,5), 'alpha_2': np.logspace(-8,-4,5), 'lambda_1': np.logspace(-8,-4,5), \n",
    "                      'lambda_2': np.logspace(-8,-4,5)},\n",
    "    'SGDRegressor': {'loss': ['squared_loss','huber','epsilon_insensitive','squared_epsilon_insensitive'], \n",
    "                     'penalty': ['l2','l1','elasticnet'], 'alpha': np.logspace(-3,-1,3),\n",
    "                     'l1_ratio': np.linspace(0.15,0.85,3), 'learning_rate': ['invscaling','adaptive']},\n",
    "    'PassiveAggressiveRegressor': {'C': np.logspace(-6,2,17)},\n",
    "    'SVR': [{'kernel': ['rbf','sigmoid'], 'C': np.logspace(-3,4,8)}, \n",
    "            {'kernel': ['poly'], 'degree': range(2,6), 'C': np.logspace(-3,4,8)}],\n",
    "    'KNeighborsRegressor': {'n_neighbors': range(3,20,1), 'weights': ['uniform','distance'], 'p': [1,2]},\n",
    "    'GradientBoostingRegressor': {'n_estimators': [800,1000,1200,1400], 'max_depth': [4,8,16,32],\n",
    "                                  'max_features': ['auto','log2']},\n",
    "    'AdaBoostRegressor': {'learning_rate': np.logspace(-3,0,5), 'n_estimators': [400,800,1000,1200,1400]},\n",
    "    'ExtraTreesRegressor': {'n_estimators': [400,800,1000,1200,1400], 'max_depth': [4,8,16,32], \n",
    "                            'max_features': ['auto','log2']},\n",
    "    'RandomForestRegressor': {'n_estimators': [800,1000,1200,1400], 'max_depth': [4,8,16,32], 'max_features': ['auto','log2']},\n",
    "    'DecisionTreeRegressor': {'min_samples_split': np.linspace(0.001,0.02,6), \n",
    "                                    'max_depth': [*range(3,21),50,150], 'max_features': ['auto','log2']},\n",
    "    'ExtraTreeRegressor': {'min_samples_split': np.linspace(0.001,0.02,6), \n",
    "                                    'max_depth': [*range(3,21),50,150], 'max_features': ['auto','log2']},\n",
    "    'MLPRegressor': {'activation': ['logistic', 'relu', 'tanh'], 'alpha': np.logspace(-5,2,4),\n",
    "    'hidden_layer_sizes': [(10,),(20,),(40,),(20,10),(40,10),(40,20),(40,20,10)]}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "LinearModels = { \n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Lasso': Lasso(random_state=seed),\n",
    "    'LassoLars': LassoLars(),\n",
    "    'Ridge': Ridge(random_state=seed),\n",
    "    'ElasticNet': ElasticNet(random_state=seed),\n",
    "    'BayesianRidge': BayesianRidge(),\n",
    "    'SGDRegressor': SGDRegressor(),\n",
    "    'PassiveAggressiveRegressor': PassiveAggressiveRegressor(random_state=seed)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluating Batter1 ***\n",
      "Running GridSearchCV for Linear Regression.\n",
      "Running GridSearchCV for Lasso.\n",
      "Running GridSearchCV for LassoLars.\n",
      "Running GridSearchCV for Ridge.\n",
      "Running GridSearchCV for ElasticNet.\n",
      "Running GridSearchCV for BayesianRidge.\n",
      "Running GridSearchCV for SGDRegressor.\n",
      "Running GridSearchCV for PassiveAggressiveRegressor.\n",
      "Done.\n",
      "*** Evaluating Batter2 ***\n",
      "Running GridSearchCV for Linear Regression.\n",
      "Running GridSearchCV for Lasso.\n",
      "Running GridSearchCV for LassoLars.\n",
      "Running GridSearchCV for Ridge.\n",
      "Running GridSearchCV for ElasticNet.\n",
      "Running GridSearchCV for BayesianRidge.\n",
      "Running GridSearchCV for SGDRegressor.\n",
      "Running GridSearchCV for PassiveAggressiveRegressor.\n",
      "Done.\n",
      "*** Evaluating Pitcher1 ***\n",
      "Running GridSearchCV for Linear Regression.\n",
      "Running GridSearchCV for Lasso.\n",
      "Running GridSearchCV for LassoLars.\n",
      "Running GridSearchCV for Ridge.\n",
      "Running GridSearchCV for ElasticNet.\n",
      "Running GridSearchCV for BayesianRidge.\n",
      "Running GridSearchCV for SGDRegressor.\n",
      "Running GridSearchCV for PassiveAggressiveRegressor.\n",
      "Done.\n",
      "*** Evaluating Pitcher2 ***\n",
      "Running GridSearchCV for Linear Regression.\n",
      "Running GridSearchCV for Lasso.\n",
      "Running GridSearchCV for LassoLars.\n",
      "Running GridSearchCV for Ridge.\n",
      "Running GridSearchCV for ElasticNet.\n",
      "Running GridSearchCV for BayesianRidge.\n",
      "Running GridSearchCV for SGDRegressor.\n",
      "Running GridSearchCV for PassiveAggressiveRegressor.\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Will select the best model for each dataset\n",
    "\n",
    "LinearModelsGS = EstimatorSelectionHelper(LinearModels, params)\n",
    "\n",
    "Lin_Mods={}\n",
    "for i in player:\n",
    "    for j in range(1,3):\n",
    "        j=str(j)\n",
    "        print(\"*** Evaluating %s%s ***\" % (i, j))\n",
    "        exec(\"LinearModelsGS.fit(\"+i+j+\"_Train_scaled, \"+i+j+\"_Target, scoring='neg_mean_squared_error', n_jobs=-1, cv=6, verbose=0)\")\n",
    "        best_model = LinearModels[LinearModelsGS.score_summary().estimator[0]]\n",
    "        best_params = LinearModelsGS.score_summary().params[0]\n",
    "        Lin_Mods[i+j] = best_model.set_params(**best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Batter1': ElasticNet(alpha=0.01, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "            max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "            random_state=1215, selection='cyclic', tol=0.0001, warm_start=False),\n",
       " 'Batter2': Lasso(alpha=0.038986037025490715, copy_X=True, fit_intercept=True,\n",
       "       max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "       random_state=1215, selection='cyclic', tol=0.0001, warm_start=False),\n",
       " 'Pitcher1': ElasticNet(alpha=0.01, copy_X=True, fit_intercept=True, l1_ratio=0.7,\n",
       "            max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "            random_state=1215, selection='cyclic', tol=0.0001, warm_start=False),\n",
       " 'Pitcher2': LassoLars(alpha=0.001, copy_X=True, eps=2.220446049250313e-16,\n",
       "           fit_intercept=True, fit_path=True, max_iter=500, normalize=True,\n",
       "           positive=False, precompute='auto', verbose=False)}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save and print the best linear models/parameters for each dataset\n",
    "\n",
    "with open('lin.p', 'wb') as fp:\n",
    "    pickle.dump(Lin_Mods, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "Lin_Mods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluating Batter1 ***\n",
      "Running GridSearchCV for DecisionTreeRegressor.\n",
      "Running GridSearchCV for ExtraTreeRegressor.\n",
      "Done.\n",
      "*** Evaluating Batter2 ***\n",
      "Running GridSearchCV for DecisionTreeRegressor.\n",
      "Running GridSearchCV for ExtraTreeRegressor.\n",
      "Done.\n",
      "*** Evaluating Pitcher1 ***\n",
      "Running GridSearchCV for DecisionTreeRegressor.\n",
      "Running GridSearchCV for ExtraTreeRegressor.\n",
      "Done.\n",
      "*** Evaluating Pitcher2 ***\n",
      "Running GridSearchCV for DecisionTreeRegressor.\n",
      "Running GridSearchCV for ExtraTreeRegressor.\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "TreeModels = { \n",
    "    'DecisionTreeRegressor': DecisionTreeRegressor(random_state=seed),\n",
    "    'ExtraTreeRegressor': ExtraTreeRegressor(random_state=seed)\n",
    "}\n",
    "\n",
    "TreeModelsGS = EstimatorSelectionHelper(TreeModels, params)\n",
    "\n",
    "Tree_Mods={}\n",
    "for i in player:\n",
    "    for j in range(1,3):\n",
    "        j=str(j)\n",
    "        print(\"*** Evaluating %s%s ***\" % (i, j))\n",
    "        exec(\"TreeModelsGS.fit(\"+i+j+\"_Train_scaled, \"+i+j+\"_Target, scoring='neg_mean_squared_error', n_jobs=-1, cv=6, verbose=0)\")\n",
    "        best_model = TreeModels[TreeModelsGS.score_summary().estimator[0]]\n",
    "        best_params = TreeModelsGS.score_summary().params[0]\n",
    "        Tree_Mods[i+j] = best_model.set_params(**best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Batter1': DecisionTreeRegressor(criterion='mse', max_depth=3, max_features='auto',\n",
       "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                       min_impurity_split=None, min_samples_leaf=1,\n",
       "                       min_samples_split=0.001, min_weight_fraction_leaf=0.0,\n",
       "                       presort=False, random_state=1215, splitter='best'),\n",
       " 'Batter2': DecisionTreeRegressor(criterion='mse', max_depth=3, max_features='auto',\n",
       "                       max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                       min_impurity_split=None, min_samples_leaf=1,\n",
       "                       min_samples_split=0.001, min_weight_fraction_leaf=0.0,\n",
       "                       presort=False, random_state=1215, splitter='best'),\n",
       " 'Pitcher1': ExtraTreeRegressor(criterion='mse', max_depth=4, max_features='auto',\n",
       "                    max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                    min_impurity_split=None, min_samples_leaf=1,\n",
       "                    min_samples_split=0.02, min_weight_fraction_leaf=0.0,\n",
       "                    random_state=1215, splitter='random'),\n",
       " 'Pitcher2': ExtraTreeRegressor(criterion='mse', max_depth=4, max_features='auto',\n",
       "                    max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                    min_impurity_split=None, min_samples_leaf=1,\n",
       "                    min_samples_split=0.02, min_weight_fraction_leaf=0.0,\n",
       "                    random_state=1215, splitter='random')}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save and print the best tree models/parameters for each dataset\n",
    "\n",
    "with open('tree.p', 'wb') as fp:\n",
    "    pickle.dump(Tree_Mods, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "Tree_Mods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluating Batter1 ***\n",
      "Running GridSearchCV for SVR.\n",
      "Done.\n",
      "*** Evaluating Batter2 ***\n",
      "Running GridSearchCV for SVR.\n",
      "Done.\n",
      "*** Evaluating Pitcher1 ***\n",
      "Running GridSearchCV for SVR.\n",
      "Done.\n",
      "*** Evaluating Pitcher2 ***\n",
      "Running GridSearchCV for SVR.\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "SVRModels = { \n",
    "    'SVR': SVR()\n",
    "}\n",
    "\n",
    "SVRModelsGS = EstimatorSelectionHelper(SVRModels, params)\n",
    "\n",
    "SVR_Mods={}\n",
    "for i in player:\n",
    "    for j in range(1,3):\n",
    "        j=str(j)\n",
    "        print(\"*** Evaluating %s%s ***\" % (i, j))\n",
    "        exec(\"SVRModelsGS.fit(\"+i+j+\"_Train_scaled, \"+i+j+\"_Target, scoring='neg_mean_squared_error', n_jobs=-1, cv=6, verbose=0)\")\n",
    "        best_model = SVRModels[SVRModelsGS.score_summary().estimator[0]]\n",
    "        best_params = SVRModelsGS.score_summary().params[0]\n",
    "        SVR_Mods[i+j] = best_model.set_params(**best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Batter1': SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
       "     gamma='auto_deprecated', kernel='rbf', max_iter=-1, shrinking=True,\n",
       "     tol=0.001, verbose=False),\n",
       " 'Batter2': SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
       "     gamma='auto_deprecated', kernel='rbf', max_iter=-1, shrinking=True,\n",
       "     tol=0.001, verbose=False),\n",
       " 'Pitcher1': SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
       "     gamma='auto_deprecated', kernel='rbf', max_iter=-1, shrinking=True,\n",
       "     tol=0.001, verbose=False),\n",
       " 'Pitcher2': SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1,\n",
       "     gamma='auto_deprecated', kernel='rbf', max_iter=-1, shrinking=True,\n",
       "     tol=0.001, verbose=False)}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save and print the best tree models/parameters for each dataset\n",
    "\n",
    "with open('svr.p', 'wb') as fp:\n",
    "    pickle.dump(SVR_Mods, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "SVR_Mods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest Neighbor Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluating Batter1 ***\n",
      "Running GridSearchCV for KNeighborsRegressor.\n",
      "Done.\n",
      "*** Evaluating Batter2 ***\n",
      "Running GridSearchCV for KNeighborsRegressor.\n",
      "Done.\n",
      "*** Evaluating Pitcher1 ***\n",
      "Running GridSearchCV for KNeighborsRegressor.\n",
      "Done.\n",
      "*** Evaluating Pitcher2 ***\n",
      "Running GridSearchCV for KNeighborsRegressor.\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "KNNModels = { \n",
    "    'KNeighborsRegressor': KNeighborsRegressor()\n",
    "}\n",
    "\n",
    "KNNModelsGS = EstimatorSelectionHelper(KNNModels, params)\n",
    "\n",
    "KNN_Mods={}\n",
    "for i in player:\n",
    "    for j in range(1,3):\n",
    "        j=str(j)\n",
    "        print(\"*** Evaluating %s%s ***\" % (i, j))\n",
    "        exec(\"KNNModelsGS.fit(\"+i+j+\"_Train_scaled, \"+i+j+\"_Target, scoring='neg_mean_squared_error', n_jobs=-1, cv=6, verbose=0)\")\n",
    "        best_model = KNNModels[KNNModelsGS.score_summary().estimator[0]]\n",
    "        best_params = KNNModelsGS.score_summary().params[0]\n",
    "        KNN_Mods[i+j] = best_model.set_params(**best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Batter1': KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=16, p=1,\n",
       "                     weights='distance'),\n",
       " 'Batter2': KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=16, p=1,\n",
       "                     weights='distance'),\n",
       " 'Pitcher1': KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=16, p=1,\n",
       "                     weights='distance'),\n",
       " 'Pitcher2': KNeighborsRegressor(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=16, p=1,\n",
       "                     weights='distance')}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save and print the best kNN models/parameters for each dataset\n",
    "\n",
    "with open('knn.p', 'wb') as fp:\n",
    "    pickle.dump(KNN_Mods, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "KNN_Mods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluating Batter1 ***\n",
      "Running GridSearchCV for MLPRegressor.\n",
      "Done.\n",
      "*** Evaluating Batter2 ***\n",
      "Running GridSearchCV for MLPRegressor.\n",
      "Done.\n",
      "*** Evaluating Pitcher1 ***\n",
      "Running GridSearchCV for MLPRegressor.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bill\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "*** Evaluating Pitcher2 ***\n",
      "Running GridSearchCV for MLPRegressor.\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "NNModels = { \n",
    "    'MLPRegressor': MLPRegressor(random_state=seed)\n",
    "}\n",
    "\n",
    "NNModelsGS = EstimatorSelectionHelper(NNModels, params)\n",
    "\n",
    "NN_Mods={}\n",
    "for i in player:\n",
    "    for j in range(1,3):\n",
    "        j=str(j)\n",
    "        print(\"*** Evaluating %s%s ***\" % (i, j))\n",
    "        exec(\"NNModelsGS.fit(\"+i+j+\"_Train_scaled, \"+i+j+\"_Target, scoring='neg_mean_squared_error', n_jobs=-1, cv=6, verbose=0)\")\n",
    "        best_model = NNModels[NNModelsGS.score_summary().estimator[0]]\n",
    "        best_params = NNModelsGS.score_summary().params[0]\n",
    "        NN_Mods[i+j] = best_model.set_params(**best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Batter1': MLPRegressor(activation='relu', alpha=100.0, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(20,), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=1215, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False),\n",
       " 'Batter2': MLPRegressor(activation='relu', alpha=100.0, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(20,), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=1215, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False),\n",
       " 'Pitcher1': MLPRegressor(activation='relu', alpha=100.0, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(20,), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=1215, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False),\n",
       " 'Pitcher2': MLPRegressor(activation='relu', alpha=100.0, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(20,), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=1215, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save and print the best Neural Network models/parameters for each dataset\n",
    "\n",
    "with open('nn.p', 'wb') as fp:\n",
    "    pickle.dump(NN_Mods, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "NN_Mods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Evaluating Batter1 ***\n",
      "Running GridSearchCV for GradientBoostingRegressor.\n",
      "Fitting 6 folds for each of 32 candidates, totalling 192 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=-1)]: Done 192 out of 192 | elapsed: 43.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for AdaBoostRegressor.\n",
      "Fitting 6 folds for each of 25 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed: 15.1min\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed: 50.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for ExtraTreesRegressor.\n",
      "Fitting 6 folds for each of 40 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-1)]: Done 188 tasks      | elapsed: 24.1min\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed: 36.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for RandomForestRegressor.\n",
      "Fitting 6 folds for each of 32 candidates, totalling 192 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:  8.4min\n",
      "[Parallel(n_jobs=-1)]: Done 192 out of 192 | elapsed: 88.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "*** Evaluating Batter2 ***\n",
      "Running GridSearchCV for GradientBoostingRegressor.\n",
      "Fitting 6 folds for each of 32 candidates, totalling 192 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed: 11.5min\n",
      "[Parallel(n_jobs=-1)]: Done 192 out of 192 | elapsed: 58.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for AdaBoostRegressor.\n",
      "Fitting 6 folds for each of 25 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed: 24.0min\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed: 85.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for ExtraTreesRegressor.\n",
      "Fitting 6 folds for each of 40 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=-1)]: Done 188 tasks      | elapsed: 41.6min\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed: 60.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for RandomForestRegressor.\n",
      "Fitting 6 folds for each of 32 candidates, totalling 192 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed: 13.4min\n",
      "[Parallel(n_jobs=-1)]: Done 192 out of 192 | elapsed: 135.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "*** Evaluating Pitcher1 ***\n",
      "Running GridSearchCV for GradientBoostingRegressor.\n",
      "Fitting 6 folds for each of 32 candidates, totalling 192 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 192 out of 192 | elapsed: 17.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for AdaBoostRegressor.\n",
      "Fitting 6 folds for each of 25 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:  8.7min\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed: 29.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for ExtraTreesRegressor.\n",
      "Fitting 6 folds for each of 40 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 188 tasks      | elapsed: 13.5min\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed: 20.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for RandomForestRegressor.\n",
      "Fitting 6 folds for each of 32 candidates, totalling 192 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-1)]: Done 192 out of 192 | elapsed: 50.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n",
      "*** Evaluating Pitcher2 ***\n",
      "Running GridSearchCV for GradientBoostingRegressor.\n",
      "Fitting 6 folds for each of 32 candidates, totalling 192 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:  5.1min\n",
      "[Parallel(n_jobs=-1)]: Done 192 out of 192 | elapsed: 20.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for AdaBoostRegressor.\n",
      "Fitting 6 folds for each of 25 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed: 12.2min\n",
      "[Parallel(n_jobs=-1)]: Done 150 out of 150 | elapsed: 46.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for ExtraTreesRegressor.\n",
      "Fitting 6 folds for each of 40 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:  2.7min\n",
      "[Parallel(n_jobs=-1)]: Done 188 tasks      | elapsed: 22.4min\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed: 32.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running GridSearchCV for RandomForestRegressor.\n",
      "Fitting 6 folds for each of 32 candidates, totalling 192 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 6 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  38 tasks      | elapsed:  8.1min\n",
      "[Parallel(n_jobs=-1)]: Done 192 out of 192 | elapsed: 74.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "BoostModels = { \n",
    "    'GradientBoostingRegressor': GradientBoostingRegressor(random_state=seed),\n",
    "    'AdaBoostRegressor': AdaBoostRegressor(random_state=seed),\n",
    "    'ExtraTreesRegressor': ExtraTreesRegressor(random_state=seed),\n",
    "    'RandomForestRegressor': RandomForestRegressor(random_state=seed)\n",
    "}\n",
    "\n",
    "BoostModelsGS = EstimatorSelectionHelper(BoostModels, params)\n",
    "\n",
    "Boost_Mods={}\n",
    "for i in player:\n",
    "    for j in range(1,3):\n",
    "        j=str(j)\n",
    "        print(\"*** Evaluating %s%s ***\" % (i, j))\n",
    "        exec(\"BoostModelsGS.fit(\"+i+j+\"_Train_scaled, \"+i+j+\"_Target, scoring='neg_mean_squared_error', n_jobs=-1, cv=6, verbose=1)\")\n",
    "        best_model = BoostModels[BoostModelsGS.score_summary().estimator[0]]\n",
    "        best_params = BoostModelsGS.score_summary().params[0]\n",
    "        Boost_Mods[i+j] = best_model.set_params(**best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Batter1': ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=8,\n",
       "                     max_features='auto', max_leaf_nodes=None,\n",
       "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                     min_samples_leaf=1, min_samples_split=2,\n",
       "                     min_weight_fraction_leaf=0.0, n_estimators=800, n_jobs=None,\n",
       "                     oob_score=False, random_state=1215, verbose=0,\n",
       "                     warm_start=False),\n",
       " 'Batter2': ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=8,\n",
       "                     max_features='auto', max_leaf_nodes=None,\n",
       "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                     min_samples_leaf=1, min_samples_split=2,\n",
       "                     min_weight_fraction_leaf=0.0, n_estimators=800, n_jobs=None,\n",
       "                     oob_score=False, random_state=1215, verbose=0,\n",
       "                     warm_start=False),\n",
       " 'Pitcher1': ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=8,\n",
       "                     max_features='auto', max_leaf_nodes=None,\n",
       "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                     min_samples_leaf=1, min_samples_split=2,\n",
       "                     min_weight_fraction_leaf=0.0, n_estimators=800, n_jobs=None,\n",
       "                     oob_score=False, random_state=1215, verbose=0,\n",
       "                     warm_start=False),\n",
       " 'Pitcher2': ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=8,\n",
       "                     max_features='auto', max_leaf_nodes=None,\n",
       "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                     min_samples_leaf=1, min_samples_split=2,\n",
       "                     min_weight_fraction_leaf=0.0, n_estimators=800, n_jobs=None,\n",
       "                     oob_score=False, random_state=1215, verbose=0,\n",
       "                     warm_start=False)}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save and print the best Boosting models/parameters for each dataset\n",
    "\n",
    "with open('boost.p', 'wb') as fp:\n",
    "    pickle.dump(Boost_Mods, fp, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "Boost_Mods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking and Blending Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet, Lasso, Ridge\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "seed = 1215\n",
    "\n",
    "train = pd.read_csv('input/Batter1Train.csv')\n",
    "test = pd.read_csv('input/Batter1Test.csv')\n",
    "\n",
    "#Save the 'playerid' and 'Name' column\n",
    "train_ID = train['playerid']\n",
    "test_ID = test['playerid']\n",
    "train_Name = train['Name']\n",
    "test_Name = test['Name']\n",
    "\n",
    "#Now drop the columns unnecessary for  the prediction process.\n",
    "train.drop(['Name', 'playerid', 'Season', 'Team'], axis = 1, inplace = True)\n",
    "test.drop(['Name', 'WAR_label', 'playerid', 'Season', 'Team'], axis = 1, inplace = True)\n",
    "\n",
    "y_train = train.WAR_label.values\n",
    "train.drop(['WAR_label'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train, y_train, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation function\n",
    "n_folds = 6\n",
    "\n",
    "def rmsle_cv(model):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=seed).get_n_splits(X_train.values)\n",
    "    rmse= np.sqrt(-cross_val_score(model, X_train.values, y_train, scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = make_pipeline(StandardScaler(), Lasso(alpha=0.03, random_state=seed))\n",
    "\n",
    "ENet = make_pipeline(StandardScaler(), ElasticNet(alpha=0.1, l1_ratio=0.3, random_state=seed))\n",
    "\n",
    "Ridge = make_pipeline(StandardScaler(), Ridge(alpha=1000.0, solver='svd'))\n",
    "\n",
    "GBoost = make_pipeline(StandardScaler(), GradientBoostingRegressor(n_estimators=1550, learning_rate=0.01, max_depth=3, \n",
    "                                                                   max_features='log2', min_samples_split=0.01, \n",
    "                                                                   random_state=seed))\n",
    "\n",
    "model_xgb = make_pipeline(StandardScaler(), xgb.XGBRegressor(colsample_bytree=0.7207, gamma=0.9, learning_rate=0.004912, \n",
    "                                                             max_depth=3, n_estimators=1100, reg_alpha=0.745, reg_lambda=0.9815, \n",
    "                                                             subsample=0.5213, silent=1, random_state=seed, nthread=-1))\n",
    "\n",
    "model_lgb = make_pipeline(StandardScaler(), lgb.LGBMRegressor(num_leaves=2, colsample_bytree=0.775, learning_rate=0.1, \n",
    "                                                              n_estimators=272, max_depth=3, random_state=seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lasso score: 1.6518 (0.0614)\n",
      "\n",
      "ElasticNet score: 1.6523 (0.0618)\n",
      "\n",
      "Ridge score: 1.6606 (0.0602)\n",
      "\n",
      "Gradient Boosting score: 1.6767 (0.0631)\n",
      "\n",
      "Xgboost score: 1.6710 (0.0593)\n",
      "\n",
      "LGBM score: 1.6742 (0.0624)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = rmsle_cv(lasso)\n",
    "print(\"\\nLasso score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "\n",
    "score = rmsle_cv(ENet)\n",
    "print(\"ElasticNet score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "\n",
    "score = rmsle_cv(Ridge)\n",
    "print(\"Ridge score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "\n",
    "score = rmsle_cv(GBoost)\n",
    "print(\"Gradient Boosting score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "\n",
    "score = rmsle_cv(model_xgb)\n",
    "print(\"Xgboost score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))\n",
    "\n",
    "score = rmsle_cv(model_lgb)\n",
    "print(\"LGBM score: {:.4f} ({:.4f})\\n\" .format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Kaggle\n",
    "class AveragingModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, models):\n",
    "        self.models = models\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.models_ = [clone(x) for x in self.models]\n",
    "        \n",
    "        # Train cloned base models\n",
    "        for model in self.models_:\n",
    "            model.fit(X, y)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        predictions = np.column_stack([\n",
    "            model.predict(X) for model in self.models_\n",
    "        ])\n",
    "        return np.mean(predictions, axis=1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Averaged base models score: 1.6518 (0.0614)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "averaged_models = AveragingModels(models = (ENet, GBoost, Ridge, lasso))\n",
    "\n",
    "score = rmsle_cv(averaged_models)\n",
    "print(\" Averaged base models score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From Kaggle\n",
    "class StackingAveragedModels(BaseEstimator, RegressorMixin, TransformerMixin):\n",
    "    def __init__(self, base_models, meta_model, n_folds=6):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "        self.n_folds = n_folds\n",
    "   \n",
    "    # We again fit the data on clones of the original models\n",
    "    def fit(self, X, y):\n",
    "        self.base_models_ = [list() for x in self.base_models]\n",
    "        self.meta_model_ = clone(self.meta_model)\n",
    "        kfold = KFold(n_splits=self.n_folds, shuffle=True, random_state=seed)\n",
    "        \n",
    "        # Train cloned base models then create out-of-fold predictions\n",
    "        # that are needed to train the cloned meta-model\n",
    "        out_of_fold_predictions = np.zeros((X.shape[0], len(self.base_models)))\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            for train_index, holdout_index in kfold.split(X, y):\n",
    "                instance = clone(model)\n",
    "                self.base_models_[i].append(instance)\n",
    "                instance.fit(X[train_index], y[train_index])\n",
    "                y_pred = instance.predict(X[holdout_index])\n",
    "                out_of_fold_predictions[holdout_index, i] = y_pred\n",
    "                \n",
    "        # Now train the cloned  meta-model using the out-of-fold predictions as new feature\n",
    "        self.meta_model_.fit(out_of_fold_predictions, y)\n",
    "        return self\n",
    "   \n",
    "    #Do the predictions of all base models on the test data and use the averaged predictions as \n",
    "    #meta-features for the final prediction which is done by the meta-model\n",
    "    def predict(self, X):\n",
    "        meta_features = np.column_stack([\n",
    "            np.column_stack([model.predict(X) for model in base_models]).mean(axis=1)\n",
    "            for base_models in self.base_models_ ])\n",
    "        return self.meta_model_.predict(meta_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Averaged models score: 1.6559 (0.0537)\n"
     ]
    }
   ],
   "source": [
    "stacked_averaged_models = StackingAveragedModels(base_models = (ENet, Ridge, GBoost, lasso),\n",
    "                                                 meta_model = model_xgb)\n",
    "\n",
    "score = rmsle_cv(stacked_averaged_models)\n",
    "print(\"Stacking Averaged models score: {:.4f} ({:.4f})\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.728524016128155\n"
     ]
    }
   ],
   "source": [
    "stacked_averaged_models.fit(X_train.values, y_train)\n",
    "stacked_val_pred = stacked_averaged_models.predict(X_val.values)\n",
    "stacked_pred = stacked_averaged_models.predict(test.values)\n",
    "print(rmsle(y_val, stacked_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7533468622447985\n"
     ]
    }
   ],
   "source": [
    "model_xgb.fit(X_train, y_train)\n",
    "xgb_val_pred = model_xgb.predict(X_val)\n",
    "xgb_pred = model_xgb.predict(test)\n",
    "print(rmsle(y_val, xgb_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7618312190085428\n"
     ]
    }
   ],
   "source": [
    "model_lgb.fit(X_train, y_train)\n",
    "lgb_val_pred = model_lgb.predict(X_val)\n",
    "lgb_pred = model_lgb.predict(test.values)\n",
    "print(rmsle(y_val, lgb_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSLE score on validation data:\n",
      "1.7292254943035485\n"
     ]
    }
   ],
   "source": [
    "'''RMSE on the validation data when averaging'''\n",
    "\n",
    "print('RMSLE score on validation data:')\n",
    "print(rmsle(y_val,stacked_val_pred*0.90 + xgb_val_pred*0.06 + lgb_val_pred*0.04 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playerid</th>\n",
       "      <th>Name</th>\n",
       "      <th>WAR_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>10155</td>\n",
       "      <td>Mike Trout</td>\n",
       "      <td>6.144684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>18401</td>\n",
       "      <td>Ronald Acuna Jr.</td>\n",
       "      <td>5.932176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>12861</td>\n",
       "      <td>Anthony Rendon</td>\n",
       "      <td>5.879208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>12533</td>\n",
       "      <td>Marcus Semien</td>\n",
       "      <td>5.707011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>13611</td>\n",
       "      <td>Mookie Betts</td>\n",
       "      <td>5.667087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>15998</td>\n",
       "      <td>Cody Bellinger</td>\n",
       "      <td>5.407620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>11477</td>\n",
       "      <td>Christian Yelich</td>\n",
       "      <td>5.368747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>17678</td>\n",
       "      <td>Alex Bregman</td>\n",
       "      <td>5.231559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>13613</td>\n",
       "      <td>Ketel Marte</td>\n",
       "      <td>4.934570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>20123</td>\n",
       "      <td>Juan Soto</td>\n",
       "      <td>4.582609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>17350</td>\n",
       "      <td>Rafael Devers</td>\n",
       "      <td>4.424788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>16505</td>\n",
       "      <td>Matt Chapman</td>\n",
       "      <td>4.211983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>12916</td>\n",
       "      <td>Francisco Lindor</td>\n",
       "      <td>4.121335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>12161</td>\n",
       "      <td>Xander Bogaerts</td>\n",
       "      <td>4.064912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>9777</td>\n",
       "      <td>Nolan Arenado</td>\n",
       "      <td>3.976765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    playerid              Name  WAR_pred\n",
       "0      10155        Mike Trout  6.144684\n",
       "1      18401  Ronald Acuna Jr.  5.932176\n",
       "2      12861    Anthony Rendon  5.879208\n",
       "3      12533     Marcus Semien  5.707011\n",
       "4      13611      Mookie Betts  5.667087\n",
       "5      15998    Cody Bellinger  5.407620\n",
       "6      11477  Christian Yelich  5.368747\n",
       "7      17678      Alex Bregman  5.231559\n",
       "8      13613       Ketel Marte  4.934570\n",
       "9      20123         Juan Soto  4.582609\n",
       "10     17350     Rafael Devers  4.424788\n",
       "11     16505      Matt Chapman  4.211983\n",
       "12     12916  Francisco Lindor  4.121335\n",
       "13     12161   Xander Bogaerts  4.064912\n",
       "14      9777     Nolan Arenado  3.976765"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1 = pd.DataFrame()\n",
    "b1['playerid'] = test_ID\n",
    "b1['Name'] = test_Name\n",
    "b1['WAR_pred'] = stacked_pred\n",
    "b1.sort_values(by='WAR_pred', ascending=False).reset_index(drop=True).head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally repeat this for the other 3 datasets..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
